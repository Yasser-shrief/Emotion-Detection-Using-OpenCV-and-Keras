{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.015714,
     "end_time": "2021-01-04T16:09:48.252450",
     "exception": false,
     "start_time": "2021-01-04T16:09:48.236736",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The data consists of 48x48 pixel grayscale images of faces. The faces have been automatically registered so that the face is more or less centered and occupies about the same amount of space in each image. The task is to categorize each face based on the emotion shown in the facial expression in to one of seven categories:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-04T16:09:48.293982Z",
     "iopub.status.busy": "2021-01-04T16:09:48.293387Z",
     "iopub.status.idle": "2021-01-04T16:09:53.231920Z",
     "shell.execute_reply": "2021-01-04T16:09:53.230753Z"
    },
    "papermill": {
     "duration": 4.964345,
     "end_time": "2021-01-04T16:09:53.232086",
     "exception": false,
     "start_time": "2021-01-04T16:09:48.267741",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# from matplotlib.pyplot import imread\n",
    "# import imageio\n",
    "from matplotlib import image\n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout, Convolution2D, Flatten, MaxPooling2D, Reshape, InputLayer\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from tensorflow.keras.preprocessing.image import load_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-04T16:09:53.267713Z",
     "iopub.status.busy": "2021-01-04T16:09:53.266964Z",
     "iopub.status.idle": "2021-01-04T16:09:53.274553Z",
     "shell.execute_reply": "2021-01-04T16:09:53.274109Z"
    },
    "papermill": {
     "duration": 0.026636,
     "end_time": "2021-01-04T16:09:53.274647",
     "exception": false,
     "start_time": "2021-01-04T16:09:53.248011",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['icml_face_data.csv',\n",
       " 'fer2013.tar.gz',\n",
       " 'example_submission.csv',\n",
       " 'train.csv',\n",
       " 'test.csv']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = '/kaggle/input/challenges-in-representation-learning-facial-expression-recognition-challenge/'\n",
    "os.listdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-04T16:09:53.312980Z",
     "iopub.status.busy": "2021-01-04T16:09:53.312440Z",
     "iopub.status.idle": "2021-01-04T16:10:00.307856Z",
     "shell.execute_reply": "2021-01-04T16:10:00.306777Z"
    },
    "papermill": {
     "duration": 7.01737,
     "end_time": "2021-01-04T16:10:00.307987",
     "exception": false,
     "start_time": "2021-01-04T16:09:53.290617",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(path+'icml_face_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-04T16:10:00.353384Z",
     "iopub.status.busy": "2021-01-04T16:10:00.352464Z",
     "iopub.status.idle": "2021-01-04T16:10:00.359731Z",
     "shell.execute_reply": "2021-01-04T16:10:00.360185Z"
    },
    "papermill": {
     "duration": 0.036361,
     "end_time": "2021-01-04T16:10:00.360308",
     "exception": false,
     "start_time": "2021-01-04T16:10:00.323947",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>Usage</th>\n",
       "      <th>pixels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Training</td>\n",
       "      <td>70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Training</td>\n",
       "      <td>151 150 147 155 148 133 111 140 170 174 182 15...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Training</td>\n",
       "      <td>231 212 156 164 174 138 161 173 182 200 106 38...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Training</td>\n",
       "      <td>24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>Training</td>\n",
       "      <td>4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   emotion     Usage                                             pixels\n",
       "0        0  Training  70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...\n",
       "1        0  Training  151 150 147 155 148 133 111 140 170 174 182 15...\n",
       "2        2  Training  231 212 156 164 174 138 161 173 182 200 106 38...\n",
       "3        4  Training  24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...\n",
       "4        6  Training  4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.016094,
     "end_time": "2021-01-04T16:10:00.392616",
     "exception": false,
     "start_time": "2021-01-04T16:10:00.376522",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    " Define training, validation and test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-04T16:10:00.435013Z",
     "iopub.status.busy": "2021-01-04T16:10:00.433070Z",
     "iopub.status.idle": "2021-01-04T16:10:00.435612Z",
     "shell.execute_reply": "2021-01-04T16:10:00.436012Z"
    },
    "papermill": {
     "duration": 0.027132,
     "end_time": "2021-01-04T16:10:00.436143",
     "exception": false,
     "start_time": "2021-01-04T16:10:00.409011",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prepare_data(data):\n",
    "    \"\"\" Prepare data for modeling \n",
    "        input: data frame with labels und pixel data\n",
    "        output: image and label array \"\"\"\n",
    "    \n",
    "    image_array = np.zeros(shape=(len(data), 48, 48))\n",
    "    image_label = np.array(list(map(int, data['emotion'])))\n",
    "    \n",
    "    for i, row in enumerate(data.index):\n",
    "        image = np.fromstring(data.loc[row, ' pixels'], dtype=int, sep=' ')\n",
    "        image = np.reshape(image, (48, 48))\n",
    "        image_array[i] = image\n",
    "        \n",
    "    return image_array, image_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.016186,
     "end_time": "2021-01-04T16:10:00.468731",
     "exception": false,
     "start_time": "2021-01-04T16:10:00.452545",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now we will be using Image Augmentation techniques om our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-04T16:10:00.513304Z",
     "iopub.status.busy": "2021-01-04T16:10:00.512278Z",
     "iopub.status.idle": "2021-01-04T16:10:04.636236Z",
     "shell.execute_reply": "2021-01-04T16:10:04.635756Z"
    },
    "papermill": {
     "duration": 4.151178,
     "end_time": "2021-01-04T16:10:04.636352",
     "exception": false,
     "start_time": "2021-01-04T16:10:00.485174",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_image_array, train_image_label = prepare_data(data[data[' Usage']=='Training'])\n",
    "val_image_array, val_image_label = prepare_data(data[data[' Usage']=='PrivateTest'])\n",
    "test_image_array, test_image_label = prepare_data(data[data[' Usage']=='PublicTest'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.016065,
     "end_time": "2021-01-04T16:10:04.669133",
     "exception": false,
     "start_time": "2021-01-04T16:10:04.653068",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Reshape and scale the images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-04T16:10:04.709002Z",
     "iopub.status.busy": "2021-01-04T16:10:04.708040Z",
     "iopub.status.idle": "2021-01-04T16:10:04.873608Z",
     "shell.execute_reply": "2021-01-04T16:10:04.873131Z"
    },
    "papermill": {
     "duration": 0.188368,
     "end_time": "2021-01-04T16:10:04.873716",
     "exception": false,
     "start_time": "2021-01-04T16:10:04.685348",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_images = train_image_array.reshape((train_image_array.shape[0], 48, 48, 1))\n",
    "X_train = train_images.astype('float32')/255\n",
    "val_images = val_image_array.reshape((val_image_array.shape[0], 48, 48, 1))\n",
    "X_val = val_images.astype('float32')/255\n",
    "test_images = test_image_array.reshape((test_image_array.shape[0], 48, 48, 1))\n",
    "X_test = test_images.astype('float32')/255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.016357,
     "end_time": "2021-01-04T16:10:04.907444",
     "exception": false,
     "start_time": "2021-01-04T16:10:04.891087",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Encoding of the target value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-04T16:10:04.944970Z",
     "iopub.status.busy": "2021-01-04T16:10:04.944436Z",
     "iopub.status.idle": "2021-01-04T16:10:04.949728Z",
     "shell.execute_reply": "2021-01-04T16:10:04.949116Z"
    },
    "papermill": {
     "duration": 0.025843,
     "end_time": "2021-01-04T16:10:04.949823",
     "exception": false,
     "start_time": "2021-01-04T16:10:04.923980",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_train = keras.utils.to_categorical(train_image_label)\n",
    "y_val = keras.utils.to_categorical(val_image_label)\n",
    "y_test = keras.utils.to_categorical(test_image_label)\n",
    "#keras.utils.to_categorical(train['label'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-04T16:10:04.997299Z",
     "iopub.status.busy": "2021-01-04T16:10:04.996664Z",
     "iopub.status.idle": "2021-01-04T16:10:05.002092Z",
     "shell.execute_reply": "2021-01-04T16:10:05.001569Z"
    },
    "papermill": {
     "duration": 0.035554,
     "end_time": "2021-01-04T16:10:05.002181",
     "exception": false,
     "start_time": "2021-01-04T16:10:04.966627",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28704</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28705</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28706</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28707</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28708</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28709 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0    1    2    3    4    5    6\n",
       "0      1.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "1      1.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "2      0.0  0.0  1.0  0.0  0.0  0.0  0.0\n",
       "3      0.0  0.0  0.0  0.0  1.0  0.0  0.0\n",
       "4      0.0  0.0  0.0  0.0  0.0  0.0  1.0\n",
       "...    ...  ...  ...  ...  ...  ...  ...\n",
       "28704  0.0  0.0  1.0  0.0  0.0  0.0  0.0\n",
       "28705  1.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "28706  0.0  0.0  0.0  0.0  1.0  0.0  0.0\n",
       "28707  1.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "28708  0.0  0.0  0.0  0.0  1.0  0.0  0.0\n",
       "\n",
       "[28709 rows x 7 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.016902,
     "end_time": "2021-01-04T16:10:05.036210",
     "exception": false,
     "start_time": "2021-01-04T16:10:05.019308",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-04T16:10:05.076597Z",
     "iopub.status.busy": "2021-01-04T16:10:05.075828Z",
     "iopub.status.idle": "2021-01-04T16:10:05.177855Z",
     "shell.execute_reply": "2021-01-04T16:10:05.177289Z"
    },
    "papermill": {
     "duration": 0.12447,
     "end_time": "2021-01-04T16:10:05.177967",
     "exception": false,
     "start_time": "2021-01-04T16:10:05.053497",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# With data augmentation to prevent overfitting\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        zoom_range = 0.1, # Randomly zoom image \n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=False,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images\n",
    "\n",
    "\n",
    "datagen.fit(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.017788,
     "end_time": "2021-01-04T16:10:05.213217",
     "exception": false,
     "start_time": "2021-01-04T16:10:05.195429",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Now Using CNN Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-04T16:10:05.254809Z",
     "iopub.status.busy": "2021-01-04T16:10:05.253122Z",
     "iopub.status.idle": "2021-01-04T16:10:05.255469Z",
     "shell.execute_reply": "2021-01-04T16:10:05.255872Z"
    },
    "papermill": {
     "duration": 0.025016,
     "end_time": "2021-01-04T16:10:05.255979",
     "exception": false,
     "start_time": "2021-01-04T16:10:05.230963",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define vars\n",
    "input_reshape = (48, 48, 1)\n",
    "\n",
    "pool_size = (2, 2)\n",
    "\n",
    "hidden_num_units = 265\n",
    "output_num_units = 7\n",
    "\n",
    "epochs = 10\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-04T16:10:05.300370Z",
     "iopub.status.busy": "2021-01-04T16:10:05.299853Z",
     "iopub.status.idle": "2021-01-04T16:10:07.975944Z",
     "shell.execute_reply": "2021-01-04T16:10:07.975442Z"
    },
    "papermill": {
     "duration": 2.702766,
     "end_time": "2021-01-04T16:10:07.976065",
     "exception": false,
     "start_time": "2021-01-04T16:10:05.273299",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3 µs, sys: 1e+03 ns, total: 4 µs\n",
      "Wall time: 5.72 µs\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "\n",
    "\n",
    "\n",
    "model = Sequential([\n",
    "\n",
    "Convolution2D(75,(2,2), activation='relu',input_shape=input_reshape),\n",
    "MaxPooling2D((2,2)),\n",
    "\n",
    "Convolution2D(50,(2,2), activation='relu'),\n",
    "MaxPooling2D((2,2)),\n",
    "\n",
    "Convolution2D(25,(2,2), activation='relu'),\n",
    "\n",
    "Flatten(),\n",
    "\n",
    "Dense(hidden_num_units, 'relu'),\n",
    "\n",
    "Dense(output_num_units,'softmax'),\n",
    " ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-04T16:10:08.018763Z",
     "iopub.status.busy": "2021-01-04T16:10:08.016161Z",
     "iopub.status.idle": "2021-01-04T16:10:08.025551Z",
     "shell.execute_reply": "2021-01-04T16:10:08.026148Z"
    },
    "papermill": {
     "duration": 0.031825,
     "end_time": "2021-01-04T16:10:08.026296",
     "exception": false,
     "start_time": "2021-01-04T16:10:07.994471",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 47, 47, 75)        375       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 23, 23, 75)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 22, 22, 50)        15050     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 11, 11, 50)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 10, 10, 25)        5025      \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2500)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 265)               662765    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 7)                 1862      \n",
      "=================================================================\n",
      "Total params: 685,077\n",
      "Trainable params: 685,077\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-04T16:10:08.075312Z",
     "iopub.status.busy": "2021-01-04T16:10:08.074482Z",
     "iopub.status.idle": "2021-01-04T16:10:32.553634Z",
     "shell.execute_reply": "2021-01-04T16:10:32.553139Z"
    },
    "papermill": {
     "duration": 24.508172,
     "end_time": "2021-01-04T16:10:32.553742",
     "exception": false,
     "start_time": "2021-01-04T16:10:08.045570",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 1.6862 - accuracy: 0.3291 - val_loss: 1.5660 - val_accuracy: 0.4087\n",
      "Epoch 2/10\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 1.4982 - accuracy: 0.4235 - val_loss: 1.4395 - val_accuracy: 0.4486\n",
      "Epoch 3/10\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 1.3745 - accuracy: 0.4751 - val_loss: 1.3671 - val_accuracy: 0.4773\n",
      "Epoch 4/10\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 1.2890 - accuracy: 0.5084 - val_loss: 1.2968 - val_accuracy: 0.4912\n",
      "Epoch 5/10\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 1.2155 - accuracy: 0.5404 - val_loss: 1.2775 - val_accuracy: 0.5082\n",
      "Epoch 6/10\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 1.1519 - accuracy: 0.5668 - val_loss: 1.2409 - val_accuracy: 0.5219\n",
      "Epoch 7/10\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 1.0918 - accuracy: 0.5927 - val_loss: 1.2570 - val_accuracy: 0.5277\n",
      "Epoch 8/10\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 1.0201 - accuracy: 0.6249 - val_loss: 1.2364 - val_accuracy: 0.5263\n",
      "Epoch 9/10\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.9443 - accuracy: 0.6542 - val_loss: 1.2402 - val_accuracy: 0.5369\n",
      "Epoch 10/10\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.8675 - accuracy: 0.6841 - val_loss: 1.2647 - val_accuracy: 0.5433\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "trained_model_conv = model.fit(X_train, y_train, epochs =epochs, batch_size=batch_size, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-04T16:10:32.817705Z",
     "iopub.status.busy": "2021-01-04T16:10:32.817006Z",
     "iopub.status.idle": "2021-01-04T16:10:33.000501Z",
     "shell.execute_reply": "2021-01-04T16:10:33.001038Z"
    },
    "papermill": {
     "duration": 0.318833,
     "end_time": "2021-01-04T16:10:33.001199",
     "exception": false,
     "start_time": "2021-01-04T16:10:32.682366",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(trained_model_conv.history['loss'],label='Train Loss')\n",
    "plt.plot(trained_model_conv.history['val_loss'],label='Val Loss')\n",
    "plt.xlabel('Ephocs')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.146448,
     "end_time": "2021-01-04T16:10:33.278073",
     "exception": false,
     "start_time": "2021-01-04T16:10:33.131625",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "I have added 2 convolutional layers each followed by an activation and then Dropout technique. 20 ephocs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-04T16:10:33.563679Z",
     "iopub.status.busy": "2021-01-04T16:10:33.558056Z",
     "iopub.status.idle": "2021-01-04T16:10:33.740652Z",
     "shell.execute_reply": "2021-01-04T16:10:33.741838Z"
    },
    "papermill": {
     "duration": 0.332447,
     "end_time": "2021-01-04T16:10:33.742032",
     "exception": false,
     "start_time": "2021-01-04T16:10:33.409585",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 48, 48, 256)       2560      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 24, 24, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 24, 24, 256)       590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 12, 12, 256)       0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 12, 12, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 12, 12, 128)       295040    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 6, 6, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 3, 3, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 3, 3, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 3, 3, 75)          86475     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 2, 2, 75)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 2, 2, 50)          33800     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 1, 1, 50)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1, 1, 50)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 1, 1, 64)          28864     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 1, 1, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 1, 1, 64)          36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 1, 1, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 1, 1, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               16640     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 7)                 1799      \n",
      "=================================================================\n",
      "Total params: 1,239,770\n",
      "Trainable params: 1,239,770\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "#Block-1\n",
    "model.add(Convolution2D(256 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu' , input_shape = input_reshape))\n",
    "model.add(MaxPooling2D((2,2) , strides = 2 , padding = 'same'))\n",
    "model.add(Convolution2D(256 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))\n",
    "model.add(MaxPooling2D((2,2) , strides = 2 , padding = 'same'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "#Block-2\n",
    "model.add(Convolution2D(128 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu' , input_shape = input_reshape))\n",
    "model.add(MaxPooling2D((2,2) , strides = 2 , padding = 'same'))\n",
    "model.add(Convolution2D(128 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))\n",
    "model.add(MaxPooling2D((2,2) , strides = 2 , padding = 'same'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "#Block-3\n",
    "model.add(Convolution2D(75 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu' , input_shape = input_reshape))\n",
    "model.add(MaxPooling2D((2,2) , strides = 2 , padding = 'same'))\n",
    "model.add(Convolution2D(50 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))\n",
    "model.add(MaxPooling2D((2,2) , strides = 2 , padding = 'same'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "#Block-4\n",
    "model.add(Convolution2D(64 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu' , input_shape = input_reshape))\n",
    "model.add(MaxPooling2D((2,2) , strides = 2 , padding = 'same'))\n",
    "model.add(Convolution2D(64 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))\n",
    "model.add(MaxPooling2D((2,2) , strides = 2 , padding = 'same'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "#Block-5\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units = 256 , activation = 'relu'))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "#Block-6\n",
    "model.add(Dense(units = 7 , activation = 'softmax'))\n",
    "model.compile(optimizer = 'adam' , loss = 'categorical_crossentropy' , metrics = ['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-04T16:10:33.999894Z",
     "iopub.status.busy": "2021-01-04T16:10:33.999027Z",
     "iopub.status.idle": "2021-01-04T16:10:34.002857Z",
     "shell.execute_reply": "2021-01-04T16:10:34.002431Z"
    },
    "papermill": {
     "duration": 0.134038,
     "end_time": "2021-01-04T16:10:34.002952",
     "exception": false,
     "start_time": "2021-01-04T16:10:33.868914",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from keras.optimizers import RMSprop,SGD,Adam\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.12727,
     "end_time": "2021-01-04T16:10:34.255162",
     "exception": false,
     "start_time": "2021-01-04T16:10:34.127892",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Before compiling i will create 3 things using keras.callbacks class:\n",
    "\n",
    "**1-Checkpoint( Function — ModelCheckpoint() )**\n",
    "\n",
    "It will monitor the validation loss and will try to minimize the loss using the mode=’min’ property. When the checkpoint is reached it will save the best trained weights. Verbose=1 is just for visualization when the code created checkpoint.Here i am using it’s following parameters:\n",
    "\n",
    "**file-path:** Path to save the model file.Here i am saving the model file with the name EmotionDetectionModel.h5\n",
    "**monitor:** Quantity to monitor.Here i am monitoring the validation loss.\n",
    "\n",
    "**mode:** One of {auto, min, max}. If save_best_only=True, the decision to overwrite the current save file is made based on either the maximization or the minimization of the monitored quantity.\n",
    "\n",
    "**save_best_only:** If save_best_only=True, the latest best model according to the quantity monitored will not be overwritten.\n",
    "**verbose:** int. 0: quiet, 1: update messages.\n",
    "\n",
    "**2-Early Stopping ( Function — EarlyStopping() )**\n",
    "\n",
    "This will stop the execution early by checking the following properties.\n",
    "\n",
    "**monitor:** Quantity to monitor.Here i am monitoring the validation loss.\n",
    "\n",
    "**min_delta:** Minimum change in the monitored quantity to qualify as an improvement, i.e. an absolute change of less than **min_delta,** will count as no improvement.Here i have given it 0.\n",
    "\n",
    "**patience:** Number of epochs with no improvement after which training will be stopped. Here i have given it 3.\n",
    "\n",
    "**restore_best_weights:** Whether to restore model weights from the epoch with the best value of the monitored quantity. If False, the model weights obtained at the last step of training are used.Here i have given it True.\n",
    "\n",
    "**verbose:** int. 0: quiet, 1: update messages.\n",
    "\n",
    "**3-Reduce Learning Rate ( Function — ReduceLROnPlateau() )**\n",
    "\n",
    "Models often benefit from reducing the learning rate by a factor of 2–10 once learning stagnates. This callback monitors a quantity and if no improvement is seen for a ‘patience’ number of epochs, the learning rate is reduced. I have used the following properties for this.\n",
    "\n",
    "**monitor**: To monitor a particular loss. Here i am monitoring the validation loss.\n",
    "\n",
    "**factor**: Factor by which the learning rate will be reduced. new_lr = lr * factor. Here i am using 0.2 as factor.\n",
    "\n",
    "**patience**: Number of epochs with no improvement after which learning rate will be reduced.Here i am using 3.\n",
    "\n",
    "**min_delta**: Threshold for measuring the new optimum, to only focus on significant changes.\n",
    "\n",
    "**verbose**: int. 0: quiet, 1: update messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-04T16:10:34.517109Z",
     "iopub.status.busy": "2021-01-04T16:10:34.515273Z",
     "iopub.status.idle": "2021-01-04T16:10:34.517676Z",
     "shell.execute_reply": "2021-01-04T16:10:34.518105Z"
    },
    "papermill": {
     "duration": 0.13591,
     "end_time": "2021-01-04T16:10:34.518221",
     "exception": false,
     "start_time": "2021-01-04T16:10:34.382311",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint('EmotionDetectionModel.h5',\n",
    "                             monitor='val_loss',\n",
    "                             mode='min',\n",
    "                             save_best_only=True,\n",
    "                             verbose=1)\n",
    "earlystop = EarlyStopping(monitor='val_loss',\n",
    "                          min_delta=0,\n",
    "                          patience=3,\n",
    "                          verbose=1,\n",
    "                          restore_best_weights=True\n",
    "                          )\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss',\n",
    "                              factor=0.2,\n",
    "                              patience=3,\n",
    "                              verbose=1,\n",
    "                              min_delta=0.0001)\n",
    "callbacks = [earlystop,checkpoint,reduce_lr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-04T16:10:34.782182Z",
     "iopub.status.busy": "2021-01-04T16:10:34.781598Z",
     "iopub.status.idle": "2021-01-04T16:12:56.746103Z",
     "shell.execute_reply": "2021-01-04T16:12:56.745625Z"
    },
    "papermill": {
     "duration": 142.100849,
     "end_time": "2021-01-04T16:12:56.746214",
     "exception": false,
     "start_time": "2021-01-04T16:10:34.645365",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "225/225 [==============================] - ETA: 0s - loss: 1.8248 - accuracy: 0.2490\n",
      "Epoch 00001: val_loss improved from inf to 1.81616, saving model to EmotionDetectionModel.h5\n",
      "225/225 [==============================] - 8s 36ms/step - loss: 1.8248 - accuracy: 0.2490 - val_loss: 1.8162 - val_accuracy: 0.2449\n",
      "Epoch 2/20\n",
      "223/225 [============================>.] - ETA: 0s - loss: 1.8118 - accuracy: 0.2515\n",
      "Epoch 00002: val_loss improved from 1.81616 to 1.81509, saving model to EmotionDetectionModel.h5\n",
      "225/225 [==============================] - 8s 34ms/step - loss: 1.8122 - accuracy: 0.2513 - val_loss: 1.8151 - val_accuracy: 0.2449\n",
      "Epoch 3/20\n",
      "223/225 [============================>.] - ETA: 0s - loss: 1.8002 - accuracy: 0.2518\n",
      "Epoch 00003: val_loss improved from 1.81509 to 1.78771, saving model to EmotionDetectionModel.h5\n",
      "225/225 [==============================] - 8s 34ms/step - loss: 1.8002 - accuracy: 0.2518 - val_loss: 1.7877 - val_accuracy: 0.2538\n",
      "Epoch 4/20\n",
      "223/225 [============================>.] - ETA: 0s - loss: 1.7186 - accuracy: 0.2938\n",
      "Epoch 00004: val_loss improved from 1.78771 to 1.64859, saving model to EmotionDetectionModel.h5\n",
      "225/225 [==============================] - 8s 35ms/step - loss: 1.7184 - accuracy: 0.2938 - val_loss: 1.6486 - val_accuracy: 0.3110\n",
      "Epoch 5/20\n",
      "223/225 [============================>.] - ETA: 0s - loss: 1.5779 - accuracy: 0.3673\n",
      "Epoch 00005: val_loss improved from 1.64859 to 1.48354, saving model to EmotionDetectionModel.h5\n",
      "225/225 [==============================] - 8s 34ms/step - loss: 1.5774 - accuracy: 0.3672 - val_loss: 1.4835 - val_accuracy: 0.3968\n",
      "Epoch 6/20\n",
      "225/225 [==============================] - ETA: 0s - loss: 1.4550 - accuracy: 0.4119\n",
      "Epoch 00006: val_loss improved from 1.48354 to 1.39277, saving model to EmotionDetectionModel.h5\n",
      "225/225 [==============================] - 8s 34ms/step - loss: 1.4550 - accuracy: 0.4119 - val_loss: 1.3928 - val_accuracy: 0.4335\n",
      "Epoch 7/20\n",
      "223/225 [============================>.] - ETA: 0s - loss: 1.3935 - accuracy: 0.4387\n",
      "Epoch 00007: val_loss improved from 1.39277 to 1.35738, saving model to EmotionDetectionModel.h5\n",
      "225/225 [==============================] - 8s 34ms/step - loss: 1.3937 - accuracy: 0.4385 - val_loss: 1.3574 - val_accuracy: 0.4547\n",
      "Epoch 8/20\n",
      "223/225 [============================>.] - ETA: 0s - loss: 1.3545 - accuracy: 0.4499\n",
      "Epoch 00008: val_loss improved from 1.35738 to 1.33952, saving model to EmotionDetectionModel.h5\n",
      "225/225 [==============================] - 8s 36ms/step - loss: 1.3541 - accuracy: 0.4499 - val_loss: 1.3395 - val_accuracy: 0.4689\n",
      "Epoch 9/20\n",
      "223/225 [============================>.] - ETA: 0s - loss: 1.3191 - accuracy: 0.4723\n",
      "Epoch 00009: val_loss improved from 1.33952 to 1.29603, saving model to EmotionDetectionModel.h5\n",
      "225/225 [==============================] - 8s 35ms/step - loss: 1.3193 - accuracy: 0.4721 - val_loss: 1.2960 - val_accuracy: 0.4848\n",
      "Epoch 10/20\n",
      "223/225 [============================>.] - ETA: 0s - loss: 1.2857 - accuracy: 0.4904\n",
      "Epoch 00010: val_loss improved from 1.29603 to 1.27974, saving model to EmotionDetectionModel.h5\n",
      "225/225 [==============================] - 8s 34ms/step - loss: 1.2863 - accuracy: 0.4904 - val_loss: 1.2797 - val_accuracy: 0.5065\n",
      "Epoch 11/20\n",
      "223/225 [============================>.] - ETA: 0s - loss: 1.2461 - accuracy: 0.5114\n",
      "Epoch 00011: val_loss improved from 1.27974 to 1.24115, saving model to EmotionDetectionModel.h5\n",
      "225/225 [==============================] - 8s 34ms/step - loss: 1.2460 - accuracy: 0.5111 - val_loss: 1.2411 - val_accuracy: 0.5224\n",
      "Epoch 12/20\n",
      "223/225 [============================>.] - ETA: 0s - loss: 1.2066 - accuracy: 0.5298\n",
      "Epoch 00012: val_loss improved from 1.24115 to 1.20718, saving model to EmotionDetectionModel.h5\n",
      "225/225 [==============================] - 8s 35ms/step - loss: 1.2065 - accuracy: 0.5298 - val_loss: 1.2072 - val_accuracy: 0.5316\n",
      "Epoch 13/20\n",
      "223/225 [============================>.] - ETA: 0s - loss: 1.1732 - accuracy: 0.5486\n",
      "Epoch 00013: val_loss did not improve from 1.20718\n",
      "225/225 [==============================] - 8s 34ms/step - loss: 1.1734 - accuracy: 0.5483 - val_loss: 1.2214 - val_accuracy: 0.5286\n",
      "Epoch 14/20\n",
      "223/225 [============================>.] - ETA: 0s - loss: 1.1379 - accuracy: 0.5653\n",
      "Epoch 00014: val_loss improved from 1.20718 to 1.19964, saving model to EmotionDetectionModel.h5\n",
      "225/225 [==============================] - 8s 34ms/step - loss: 1.1377 - accuracy: 0.5657 - val_loss: 1.1996 - val_accuracy: 0.5414\n",
      "Epoch 15/20\n",
      "223/225 [============================>.] - ETA: 0s - loss: 1.1124 - accuracy: 0.5732\n",
      "Epoch 00015: val_loss improved from 1.19964 to 1.16985, saving model to EmotionDetectionModel.h5\n",
      "225/225 [==============================] - 8s 34ms/step - loss: 1.1124 - accuracy: 0.5733 - val_loss: 1.1698 - val_accuracy: 0.5528\n",
      "Epoch 16/20\n",
      "223/225 [============================>.] - ETA: 0s - loss: 1.0940 - accuracy: 0.5832\n",
      "Epoch 00016: val_loss did not improve from 1.16985\n",
      "225/225 [==============================] - 8s 34ms/step - loss: 1.0940 - accuracy: 0.5833 - val_loss: 1.2028 - val_accuracy: 0.5497\n",
      "Epoch 17/20\n",
      "224/225 [============================>.] - ETA: 0s - loss: 1.0693 - accuracy: 0.5914\n",
      "Epoch 00017: val_loss did not improve from 1.16985\n",
      "225/225 [==============================] - 8s 34ms/step - loss: 1.0692 - accuracy: 0.5915 - val_loss: 1.2014 - val_accuracy: 0.5461\n",
      "Epoch 18/20\n",
      "223/225 [============================>.] - ETA: 0s - loss: 1.0510 - accuracy: 0.6045Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 1.16985\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "225/225 [==============================] - 8s 34ms/step - loss: 1.0508 - accuracy: 0.6047 - val_loss: 1.1766 - val_accuracy: 0.5614\n",
      "Epoch 00018: early stopping\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "trained_model_conv = model.fit(X_train, y_train, epochs =20, batch_size=128,callbacks=callbacks, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-04T16:12:58.131966Z",
     "iopub.status.busy": "2021-01-04T16:12:58.130828Z",
     "iopub.status.idle": "2021-01-04T16:12:58.276612Z",
     "shell.execute_reply": "2021-01-04T16:12:58.277079Z"
    },
    "papermill": {
     "duration": 0.842672,
     "end_time": "2021-01-04T16:12:58.277232",
     "exception": false,
     "start_time": "2021-01-04T16:12:57.434560",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(trained_model_conv.history['loss'],label='Train Loss')\n",
    "plt.plot(trained_model_conv.history['val_loss'],label='Val Loss')\n",
    "plt.xlabel('Ephocs')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.690782,
     "end_time": "2021-01-04T16:12:59.667237",
     "exception": false,
     "start_time": "2021-01-04T16:12:58.976455",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Driver Code\n",
    "\n",
    "Now i’ll explain the code for Emotion Detection using the model that i created in the above section.\n",
    "\n",
    "Now we have the engine and the only thing left to make is the body so that our software is complete.\n",
    "\n",
    "First let’s once more import some modules that are need to run the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.preprocessing import image\n",
    "import cv2\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let’s load the model and also load a classifier that i have used to detect the face of a person in-front of the camera. \n",
    "I have used the haarcascade_frontalface_default classifier. Haar Cascade is a machine learning object detection algorithm used to identify objects in an image or video and based on the concept of​​ features proposed by Paul Viola and Michael Jones in their paper “Rapid Object Detection using a Boosted Cascade of Simple Features” in 2001. \n",
    "The haarcascade_frontalface_default classifier detects the front face of a person in an image or a continuous video feed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_classifier=cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "#cascadePath = \"haarcascade_frontalface_default.xml\"\n",
    "classifier = keras.models.load_model('EmotionDetectionModel.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now i’ll define a variable class_labels to store the name of the classes or the types of emotions we are going to predict\n",
    "\n",
    "and also a variable cap to store the value returned by the cv2.VideoCapture method. \n",
    "\n",
    "Here the value 0 in VideoCapture is used to instruct the method to use the primary webcam of a laptop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_labels=['Angry','Happy','Neutral','Sad','Surprise']\n",
    "cap=cv2.VideoCapture(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Now i’ll explain the code to make boxes around the faces detected by the classifier in the camera feed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    ret,frame=cap.read()\n",
    "    labels=[]\n",
    "    gray=cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "    faces=face_classifier.detectMultiScale(gray,1.3,5)\n",
    "\n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(frame,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "        roi_gray=gray[y:y+h,x:x+w]\n",
    "        roi_gray=cv2.resize(roi_gray,(48,48),interpolation=cv2.INTER_AREA)\n",
    "\n",
    "        if np.sum([roi_gray])!=0:\n",
    "            roi=roi_gray.astype('float')/255.0\n",
    "            roi=img_to_array(roi)\n",
    "            roi=np.expand_dims(roi,axis=0)\n",
    "\n",
    "            preds=classifier.predict(roi)[0]\n",
    "            label=class_labels[preds.argmax()]\n",
    "            label_position=(x,y)\n",
    "            cv2.putText(frame,label,label_position,cv2.FONT_HERSHEY_SIMPLEX,2,(0,255,0),3)\n",
    "        else:\n",
    "            cv2.putText(frame,'No Face Found',(20,20),cv2.FONT_HERSHEY_SIMPLEX,2,(0,255,0),3)\n",
    "    \n",
    "    cv2.imshow('Emotion Detector',frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "papermill": {
   "duration": 197.827049,
   "end_time": "2021-01-04T16:13:02.357427",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-01-04T16:09:44.530378",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
